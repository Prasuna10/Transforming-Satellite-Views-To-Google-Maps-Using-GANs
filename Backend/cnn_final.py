# -*- coding: utf-8 -*-
"""CNN_final (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VBIsK2fhmpOlNnV8Tjv4u5TJ-KIp6GgV
"""

!pip install --upgrade tensorflow

!pip install tensorflow==2.15.0

!pip install --upgrade tf-keras

import tensorflow as tf
print(tf.__version__)

!pip install --upgrade tf-keras

# Install virtualenv
!pip install virtualenv

# Create a virtual environment
!virtualenv myenv

# Activate the virtual environment
!source myenv/bin/activate

from google.colab import drive
drive.mount('/content/drive')

!cp -r /content/drive/MyDrive/maps.zip /content

!unzip maps.zip

import matplotlib.pyplot as plt
import numpy as np
from glob import glob
import time

import tensorflow as tf
from tensorflow import keras
from keras import Sequential
from keras.models import Model
from keras.layers import Conv2D, Input, MaxPool2D, Conv2DTranspose, concatenate, Lambda, BatchNormalization, Activation, LeakyReLU, ReLU
from keras.utils import img_to_array, load_img, plot_model
from keras.optimizers import Adam
from keras.initializers import RandomNormal
from keras.layers import Input, Dense, Dropout, BatchNormalization, Conv2D, MaxPooling2D, UpSampling2D
from keras import layers, losses, optimizers
from sklearn.metrics import confusion_matrix, f1_score, recall_score, accuracy_score, precision_score
import seaborn as sns

path = "maps/train/"
num_images = 1000

combined_images = sorted(glob(path + "*.jpg"))[:num_images]

images = np.zeros(shape=(len(combined_images), 256, 256, 3))
masks = np.zeros(shape=(len(combined_images), 256, 256, 3))

for idx, path in enumerate(combined_images):

    combined_image = tf.cast(img_to_array(load_img(path)), tf.float32)

    image = combined_image[:,:600,:]
    mask = combined_image[:,600:,:]

    images[idx] = (tf.image.resize(image,(256,256)))/255
    masks[idx] = (tf.image.resize(mask,(256,256)))/255

plt.figure(figsize=(25,10))
for i in range(1,6):
    idx = np.random.randint(1,1000)
    image, mask = images[idx], masks[idx]
    plt.subplot(2,5,i)
    plt.imshow(image)
    plt.savefig("/content/drive/MyDrive/image.jpg")
    plt.title(str(i) + " .Satellite image")
    plt.axis("off")
    plt.subplot(2,5,i + 5)
    plt.imshow(mask)
    plt.title(str(i) + " .Map ")
    plt.axis("off")
plt.show()

sat_image, map_image = tf.cast(images, tf.float32), tf.cast(masks, tf.float32)
dataset = (sat_image,map_image)
data = tf.data.Dataset.from_tensor_slices(dataset).batch(32, drop_remainder=True)

import tensorflow as tf
import keras
from keras.layers import Input, Dense, Dropout, BatchNormalization, Conv2D, MaxPooling2D, UpSampling2D
from keras import layers, losses, optimizers
# Define the CNN-based model
def SatelliteToMapsModel():
    inputs = Input(shape=(256, 256, 3))

    # Encoder
    conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)
    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)
    conv2 = Conv2D(128, 3, activation='relu', padding='same')(pool1)
    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)

    # Decoder
    conv3 = Conv2D(128, 3, activation='relu', padding='same')(pool2)
    up1 = UpSampling2D((2, 2))(conv3)
    drop1 = Dropout(rate=0.5)(up1)
    conv4 = Conv2D(64, 3, activation='relu', padding='same')(drop1)
    drop2 = Dropout(rate=0.5)(conv4)
    up2 = UpSampling2D((2, 2))(conv4)
    # Output layer
    model = tf.keras.Sequential([
    Dense(16, input_shape=(1,5), activation='relu'),
    BatchNormalization(),
    Dense(32, activation='relu'),
    BatchNormalization(),
    Dense(2, activation='softmax')])
    outputs = Conv2D(3, 3, activation='sigmoid', padding='same')(up2)

    model = tf.keras.Model(inputs=inputs, outputs=outputs)
    return model

# Define loss function
def pixelwise_mse(y_true, y_pred):
    return tf.keras.losses.mean_squared_error(y_true, y_pred)

# Create the model
model = SatelliteToMapsModel()

model.summary()

model = SatelliteToMapsModel()

from keras.metrics import Accuracy

# Define the loss function
model.compile(optimizer=optimizers.Adam(), loss=pixelwise_mse, metrics=['accuracy', Accuracy()])

# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
history = model.fit(sat_image, map_image, batch_size=32, epochs=100, validation_split=0.2)

plt.figure(figsize=(12, 6))

# Plot training loss
plt.subplot(1, 2, 1)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

# Plot validation accuracy
plt.subplot(1, 2, 2)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

plt.show()

# Evaluate the model
predictions = model.predict(sat_image)

# Flatten the predictions and ground truth masks
predictions_flat = tf.reshape(predictions, [-1, 3])
map_image_flat = tf.reshape(map_image, [-1, 3])

# Threshold the predictions (assuming binary classification)
predictions_binary = tf.cast(predictions_flat > 0.5, dtype=tf.int32)
map_image_binary = tf.cast(map_image_flat > 0.5, dtype=tf.int32)

import numpy as np

# Convert TensorFlow tensors to NumPy arrays
map_image_binary_np = map_image_binary.numpy().flatten()
predictions_binary_np = predictions_binary.numpy().flatten()

# Compute metrics
conf_matrix = confusion_matrix(map_image_binary_np, predictions_binary_np)
precision = precision_score(map_image_binary_np, predictions_binary_np)
recall = recall_score(map_image_binary_np, predictions_binary_np)
accuracy = accuracy_score(map_image_binary_np, predictions_binary_np)
f1 = f1_score(map_image_binary_np, predictions_binary_np)

print("Confusion Matrix:")
print(conf_matrix)
print("Precision:", precision)
print("Recall:", recall)
print("Accuracy:", accuracy)
print("F1 Score:", f1)

from sklearn.metrics import f1_score, recall_score, accuracy_score, precision_score

def evaluate_model(model, images, masks):
    predictions = model.predict(images)

    # Apply thresholding to convert probabilities to binary values
    threshold = 0.5
    predictions_binary = (predictions > threshold).astype(np.uint8)

    # Flatten masks and predictions
    masks_flat = masks.reshape(-1, 256, 256, 3)
    predictions_flat = predictions_binary.reshape(-1, 256, 256, 1)

    # Compute metrics
    f1 = f1_score(masks_flat.flatten(), predictions_flat.flatten())
    recall = recall_score(masks_flat.flatten(), predictions_flat.flatten())
    accuracy = accuracy_score(masks_flat.flatten(), predictions_flat.flatten())
    precision = precision_score(masks_flat.flatten(), predictions_flat.flatten())

    # Compute confusion matrix
    conf_matrix = confusion_matrix(masks_flat.flatten(), predictions_flat.flatten())

    return f1, recall, accuracy, precision, conf_matrix

# Convert tensors to NumPy arrays
sat_image_np = sat_image.numpy()
map_image_np = map_image.numpy()

f1, recall, accuracy, precision, conf_matrix = evaluate_model(model, sat_image_np, map_image_np)

print("F1 Score:", f1)
print("Recall:", recall)
print("Accuracy:", accuracy)
print("Precision:", precision)
print("Confusion Matrix:")
print(conf_matrix)

model.save('/content/drive/MyDrive/modl.h5')

def calculate_iou(y_true, y_pred):
    intersection = np.logical_and(y_true, y_pred)
    union = np.logical_or(y_true, y_pred)
    iou_score = np.sum(intersection) / np.sum(union)
    return iou_score

def show_predictions(num_samples):
    total_iou=0
    for i in range(num_samples):
        idx = np.random.randint(images.shape[0])
        image, mask = images[idx], masks[idx]
        predicted = model.predict(tf.expand_dims(image, axis=0))[0]
        predicted_binary = (predicted > 0.5).astype(np.uint8)
        iou = calculate_iou(mask, predicted_binary)
        total_iou += iou

        plt.figure(figsize=(10,8))

        plt.subplot(1,3,1)
        plt.imshow(image)
        plt.title("Satellite Image " + str(i + 1))
        plt.axis('off')

        plt.subplot(1,3,2)
        plt.imshow(mask)
        plt.title("Map Image " + str(i + 1))
        plt.axis('off')

        plt.subplot(1,3,3)
        plt.imshow(predicted)
        plt.title("Predicted Image " + str(i + 1))
        plt.axis('off')

        plt.show()
    mean_iou = total_iou / num_samples
    print("Mean IoU:", mean_iou)

show_predictions(3)